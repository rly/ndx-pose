def test_example_usage():
    import datetime
    import numpy as np
    from pynwb import NWBFile, NWBHDF5IO
    from ndx_pose import PoseEstimationSeries, PoseEstimation, Skeleton, Instance, TrainingFrame, PoseTraining
    from pynwb.image import ImageSeries

    nwbfile = NWBFile(
        session_description='session_description',
        identifier='identifier',
        session_start_time=datetime.datetime.now(datetime.timezone.utc)
    )

    camera1 = nwbfile.create_device(
        name='camera1',
        description='left camera',
        manufacturer='my manufacturer'
    )

    data = np.random.rand(100, 3)  # num_frames x (x, y, z)
    timestamps = np.linspace(0, 10, num=100)  # a timestamp for every frame
    confidence = np.random.rand(100)  # a confidence value for every frame
    front_left_paw = PoseEstimationSeries(
        name='front_left_paw',
        description='Marker placed around fingers of front left paw.',
        data=data,
        unit='pixels',
        reference_frame='(0,0,0) corresponds to ...',
        timestamps=timestamps,
        confidence=confidence,
        confidence_definition='Softmax output of the deep neural network.',
    )

    data = np.random.rand(100, 3)  # num_frames x (x, y, z)
    timestamps = np.linspace(0, 10, num=100)  # a timestamp for every frame
    confidence = np.random.rand(100)  # a confidence value for every frame
    body = PoseEstimationSeries(
        name='body',
        description='Marker placed on center of body.',
        data=data,
        unit='pixels',
        reference_frame='(0,0,0) corresponds to ...',
        timestamps=front_left_paw,  # link to timestamps of front_left_paw
        confidence=confidence,
        confidence_definition='Softmax output of the deep neural network.',
    )

    data = np.random.rand(100, 2)  # num_frames x (x, y)
    timestamps = np.linspace(0, 10, num=100)  # a timestamp for every frame
    confidence = np.random.rand(100)  # a confidence value for every frame
    front_right_paw = PoseEstimationSeries(
        name='front_right_paw',
        description='Marker placed around fingers of front right paw.',
        data=data,
        unit='pixels',
        reference_frame='(0,0,0) corresponds to ...',
        timestamps=front_left_paw,  # link to timestamps of front_left_paw
        confidence=confidence,
        confidence_definition='Softmax output of the deep neural network.',
    )

    pose_estimation_series = [front_left_paw, body, front_right_paw]

    skeleton = Skeleton(
        id="subject1",
        nodes=['front_left_paw', 'body', 'front_right_paw'],
        # edge between front left paw and body, edge between body and front right paw
        edges=np.array([[0, 1], [1, 2]], dtype='uint8'),
    )

    # create a PoseEstimation object that represents the estimated positions of the front paws and body
    # from DLC and references the original videos simultaneously recorded from two cameras and the labeled
    # videos that were generated by DLC.
    pose_estimation = PoseEstimation(
        pose_estimation_series=pose_estimation_series,
        description='Estimated positions of front paws using DeepLabCut.',
        original_videos=['camera1.mp4'],
        labeled_videos=['camera1_labeled.mp4'],
        dimensions=np.array([[640, 480]], dtype='uint16'),
        scorer='DLC_resnet50_openfieldOct30shuffle1_1600',
        source_software='DeepLabCut',
        source_software_version='2.2b8',
        skeleton=skeleton,
        cameras=[camera1],
    )

    training_video1 = ImageSeries(
        name='source_video',
        unit='NA',
        format='external',
        external_file=['camera1.mp4'],
        dimension=[640, 480],
        starting_frame=[0],
        rate=30.0,
        description='Training video used to train the pose estimation model.',
    )

    # create 50 ground truth instances of the skeleton at slightly random positions.
    # in this example, each node is visible on every frame.
    # the mapping of index in node_locations and node_visibilities to label is defined by the skeleton.
    instances = []
    for i in range(50):
        node_locations = np.array([
            [10, 10],  # front_left_paw
            [20, 20],  # body
            [30, 10],  # front_right_paw
        ])
        node_locations = node_locations + np.random.rand(3, 2)  # add some noise
        instances.append(
            Instance(
                id=np.uint(i),
                node_locations=node_locations,
                node_visibility=[
                    True,  # front_left_paw
                    True,  # body
                    True,  # front_right_paw
                ],
                skeleton=skeleton,  # link to the skeleton
            )
        )

    # create 50 training frames using the training video and the instances
    # the instances start with video frame 0 and end with video frame 99
    training_frames = []
    for i in range(50):
        training_frames.append(
            TrainingFrame(
                name="frame_{}".format(i),  # names must be unique when added to a PoseTraining object
                annotator="Bilbo Baggins",
                instance=instances[i],
                source_video=training_video1,
                source_video_frame_index=np.uint(i),
            )
        )

    # store the skeleton, the training frames, and ground truth annotations in a PoseTraining object
    pose_training = PoseTraining(
        skeletons=[skeleton],
        training_frames=training_frames,
        source_videos=[training_video1],
    )

    behavior_pm = nwbfile.create_processing_module(
        name='behavior',
        description='processed behavioral data'
    )
    behavior_pm.add(pose_estimation)
    behavior_pm.add(pose_training)

    path = 'test_pose.nwb'
    with NWBHDF5IO(path, mode='w') as io:
        io.write(nwbfile)

    with NWBHDF5IO(path, mode='r', load_namespaces=True) as io:
        read_nwbfile = io.read()
        read_pe = read_nwbfile.processing['behavior']['PoseEstimation']
        print(read_pe)
        read_pt = read_nwbfile.processing['behavior']['PoseTraining']
        print(read_pt)
        print(read_pt.training_frames["frame_0"])
